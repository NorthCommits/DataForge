{"url": "https://ieeexplore.ieee.org/document/10542617", "title": "Hallucinations in Large Language Models (LLMs) - IEEE Xplore", "content": "Hallucinations in Large Language Models (LLMs) | IEEE Conference Publication | IEEE Xplore The recent advancements in neural network architectures, particularly transformers, have played a crucial role in the rapid progress of Large Language Models (LLMs). The recent advancements in neural network architectures, particularly transformers, have played a crucial role in the rapid progress of Large Language Models (LLMs). These models have enabled machines to generate new data (human-like), driving significant developments in Natural Language Processing (NLP). Large Language Models (LLMs) are a kind of AI that are trained on huge datasets [9], [10]. LLMs are advanced NLP (Natural Language Processing) models that use a deep neural network architecture designed to understand, generate, and process human language at a sophisticated level [11].", "score": 0.849865, "scraped_at": "2025-10-28T20:34:34.958915"}
{"url": "https://www.baeldung.com/cs/llm-fix-hallucinations-why-happen", "title": "Hallucinations in Large Language Models: Causes, Challenges ...", "content": "Causes of Hallucinations in Large Language Models # Hallucinations in Large Language Models: Causes, Challenges, and Mitigation Weâ€™ll cover aspects like the training data and the probabilistic nature of large language models. **Large language models can generate responses that seem logical or coherent but contain incorrect or inconsistent information. Causes of Hallucinations in Large Language Models Some methods can help mitigate hallucinations in large language models. **By letting models check their responses against outside sources of quality information, we can significantly reduce hallucinations.** In this article, we learned that hallucinations are a significant challenge in large language models. The inherent limits of the training data and model architecture cause this problem. To tackle these challenges, we need better training data, model architectures that handle ambiguities, and real-time fact-checking.", "score": 0.772805, "scraped_at": "2025-10-28T20:34:34.958948"}
{"url": "https://medium.com/@tam.tamanna18/understanding-llm-hallucinations-causes-detection-prevention-and-ethical-concerns-914bc89128d0", "title": "Understanding LLM Hallucinations. Causes, Detection, Prevention ...", "content": "LLM hallucinations occur when a model generates text that is factually incorrect, inconsistent, or entirely made up.", "score": 0.8477600000000001, "scraped_at": "2025-10-28T20:34:34.958980"}
